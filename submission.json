json
{
  "candidate": {
    "name": "Rahul Kumar",
    "email": "rahul.kumar.pg24@nsut.ac.in"
  },
  "section_a": {
    "issues": [
      {
        "bug": "Race condition between inventory check and update",
        "failure_scenario": "Two users simultaneously buy the last item in stock (stock=1). Both requests pass the stock check (product.stock < item.quantity is false since stock=1 and quantity=1), then both proceed to decrement stock.",
        "consequence": "Overselling - inventory goes negative (-1), two customers get charged for an item you don't have, customer service nightmare",
        "fix": "Use SELECT FOR UPDATE or optimistic concurrency control with a version field. Wrap the entire operation in a database transaction. Prisma supports $transaction() which serializes execution."
      },
      {
        "bug": "No database transaction wrapping the critical operations",
        "failure_scenario": "Payment succeeds, order is created, but the server crashes or loses connection before inventory updates complete.",
        "consequence": "Inconsistent state - user is charged and has an order, but inventory isn't decremented. Also, if order creation fails after payment, user is charged with no order record.",
        "fix": "Wrap payment verification, order creation, and inventory updates in a single transaction. Consider using saga pattern for payment to support compensation if downstream steps fail."
      },
      {
        "bug": "Payment processed before creating order record",
        "failure_scenario": "Payment API returns success, but Prisma fails to create the order due to a constraint violation or database issue.",
        "consequence": "User is charged but receives no order. No record to reconcile against. Business loses customer trust.",
        "fix": "Create the order in 'pending' status first within a transaction, then process payment. Update order status to 'confirmed' only after successful payment. Use transaction IDs to track payment attempts."
      },
      {
        "bug": "No idempotency mechanism",
        "failure_scenario": "User double-clicks the checkout button, or network timeout causes them to retry the request. Both requests are processed.",
        "consequence": "Duplicate orders, duplicate charges, double inventory decrement. Financial reconciliation becomes painful.",
        "fix": "Accept an idempotency key in the request header. Check if a previous order exists with the same key for this customer. Return cached result if found."
      },
      {
        "bug": "External payment API has no timeout configuration",
        "failure_scenario": "The payment provider experiences a slowdown and takes 60+ seconds to respond. The request hangs, keeping a database connection open.",
        "consequence": "Resource exhaustion - all workers tied up waiting, queue backs up, service becomes unavailable. Potential cascading failure.",
        "fix": "Add timeout configuration to fetch() (e.g., 10 seconds). Consider using a circuit breaker pattern to fail fast when the payment service is degraded."
      },
      {
        "bug": "Sequential inventory updates aren't atomic",
        "failure_scenario": "Order has 5 items. First 4 inventory updates succeed, 5th fails due to a deadlock or constraint violation.",
        "consequence": "Partial inventory update - order created but some items still have incorrect stock. Data corruption that requires manual reconciliation.",
        "fix": "All inventory updates must be within the same transaction as order creation. Use Prisma's $transaction to ensure all-or-nothing."
      },
      {
        "bug": "No input validation on quantities and customer data",
        "failure_scenario": "Malicious client sends negative quantity (-10) or zero quantity. Or sends malformed productId.",
        "consequence": "Negative quantity check passes (stock < -10 is usually true), leading to logic errors or database errors. Could expose system internals through error messages.",
        "fix": "Add validation layer at the API boundary using a library like Zod or Joi. Validate quantities > 0, required fields present, IDs are valid UUIDs."
      },
      {
        "bug": "Email sending is fire-and-forget with no retry",
        "failure_scenario": "Email service is temporarily down when order completes. Customer gets no confirmation.",
        "consequence": "Poor UX - customer doesn't know if order went through, may retry purchase. No notification of order success.",
        "fix": "Move email sending to a background queue (Bull, SQS). Implement retry logic with exponential backoff. Log failures for monitoring."
      }
    ]
  },
  "section_b": {
    "endpoints": [
      {
        "method": "POST",
        "path": "/api/auth/register",
        "description": "Register a new user account",
        "request": {
          "email": "string",
          "password": "string",
          "name": "string"
        },
        "response": {
          "userId": "string",
          "email": "string"
        },
        "errors": [
          { "code": 400, "message": "Invalid email format" },
          { "code": 409, "message": "Email already registered" }
        ]
      },
      {
        "method": "POST",
        "path": "/api/files/upload",
        "description": "Upload a file (multipart/form-data, max 100MB)",
        "request": {
          "file": "binary",
          "filename": "string",
          "folderId": "string (optional)"
        },
        "response": {
          "fileId": "string",
          "url": "string",
          "size": "number"
        },
        "errors": [
          { "code": 413, "message": "File too large (max 100MB)" },
          { "code": 429, "message": "Rate limit exceeded" }
        ]
      },
      {
        "method": "POST",
        "path": "/api/files/upload/chunked",
        "description": "Initiate chunked upload for better reliability",
        "request": {
          "filename": "string",
          "size": "number",
          "contentType": "string"
        },
        "response": {
          "uploadId": "string",
          "chunkSize": 5242880
        }
      },
      {
        "method": "PUT",
        "path": "/api/files/upload/chunked/{uploadId}/{chunkNumber}",
        "description": "Upload a single chunk",
        "request": "binary data",
        "response": {
          "received": true
        }
      },
      {
        "method": "POST",
        "path": "/api/files/upload/chunked/{uploadId}/complete",
        "description": "Complete chunked upload and assemble file",
        "request": {
          "chunks": [1, 2, 3, 4, 5]
        },
        "response": {
          "fileId": "string",
          "url": "string"
        }
      },
      {
        "method": "POST",
        "path": "/api/files/{fileId}/share",
        "description": "Create a share link for a file",
        "request": {
          "password": "string (optional)",
          "expiresAt": "ISO8601 datetime (optional)",
          "maxDownloads": "number (optional)"
        },
        "response": {
          "shareId": "string",
          "shareUrl": "https://share.service/s/{shareId}",
          "expiresAt": "string (optional)"
        },
        "errors": [
          { "code": 404, "message": "File not found" },
          { "code": 403, "message": "Not your file" }
        ]
      },
      {
        "method": "DELETE",
        "path": "/api/files/{fileId}/share/{shareId}",
        "description": "Revoke a share link",
        "request": {},
        "response": {
          "revoked": true
        }
      },
      {
        "method": "GET",
        "path": "/api/share/{shareId}",
        "description": "Get file metadata (before download)",
        "request": {},
        "response": {
          "filename": "string",
          "size": "number",
          "contentType": "string",
          "requiresPassword": true
        },
        "errors": [
          { "code": 404, "message": "Link not found or expired" },
          { "code": 410, "message": "Download limit reached or file revoked" }
        ]
      },
      {
        "method": "POST",
        "path": "/api/share/{shareId}/unlock",
        "description": "Unlock password-protected link",
        "request": {
          "password": "string"
        },
        "response": {
          "downloadToken": "jwt token for actual download"
        },
        "errors": [
          { "code": 401, "message": "Invalid password" }
        ]
      },
      {
        "method": "GET",
        "path": "/api/share/{shareId}/download",
        "description": "Download the actual file (stream)",
        "request": {
          "headers": {
            "Authorization": "Bearer downloadToken (if password protected)"
          }
        },
        "response": "binary stream",
        "errors": [
          { "code": 401, "message": "Invalid or expired download token" }
        ]
      },
      {
        "method": "GET",
        "path": "/api/files",
        "description": "List user's files",
        "request": {
          "page": "number",
          "limit": "number",
          "folderId": "string (optional)"
        },
        "response": {
          "files": [
            { "id": "string", "filename": "string", "size": "number", "createdAt": "string" }
          ],
          "total": 100
        }
      },
      {
        "method": "GET",
        "path": "/api/files/{fileId}/downloads/audit",
        "description": "Get download audit log (file owner only)",
        "request": {},
        "response": {
          "downloads": [
            { "timestamp": "string", "ip": "string", "userAgent": "string", "shareId": "string" }
          ]
        },
        "errors": [
          { "code": 403, "message": "Not your file" }
        ]
      }
    ],
    "error_handling": "Use standard HTTP status codes. For partial failures (e.g., chunked upload), return specific chunk numbers that need retry. Always include correlation IDs for tracing. For rate limiting, return Retry-After header.",
    "security": "Authenticate users with JWT tokens stored in HttpOnly cookies. For share links, use short-lived download tokens (30 minutes) generated after password verification. Rate limiting using token bucket algorithm: 100 requests/minute for authenticated users, 20/minute for anonymous downloads. Store audit logs asynchronously to avoid blocking requests. Password-protected files should use constant-time comparison for passwords to prevent timing attacks.",
    "edge_cases": {
      "file_deleted_during_download": "Allow the download to complete if it already started. Check file existence at the start of the request. If file was soft-deleted, still serve from storage but mark as deleted in audit logs.",
      "rate_limit_mid_upload": "For chunked uploads, enforce rate limit at the chunk initiation phase, not during individual chunk uploads. Once uploadId is created, allow reasonable time to complete (e.g., 24 hours). Return 429 with clear message for new uploads.",
      "password_changed_with_old_link": "Share links should reference the file, not the password. Changing password updates the link's password requirement. Old links still work but require new password. The link itself doesn't change. If owner wants to invalidate all old links, they must revoke and create new share."
    }
  },
  "section_c": {
    "schema": "CREATE TABLE organizations (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  name VARCHAR(255) NOT NULL,\n  plan VARCHAR(50) NOT NULL DEFAULT 'free',\n  created_at TIMESTAMP DEFAULT NOW(),\n  retention_days INTEGER NOT NULL DEFAULT 90\n);\n\nCREATE TABLE users (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  org_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,\n  email VARCHAR(255) NOT NULL UNIQUE,\n  role VARCHAR(50) NOT NULL DEFAULT 'viewer',\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE events (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  org_id UUID NOT NULL REFERENCES organizations(id),\n  user_id UUID,\n  event_name VARCHAR(100) NOT NULL,\n  properties JSONB NOT NULL DEFAULT '{}',\n  timestamp TIMESTAMP NOT NULL DEFAULT NOW(),\n  received_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE dashboards (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  org_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,\n  name VARCHAR(255) NOT NULL,\n  created_by UUID REFERENCES users(id),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE widgets (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  dashboard_id UUID NOT NULL REFERENCES dashboards(id) ON DELETE CASCADE,\n  type VARCHAR(50) NOT NULL,\n  config JSONB NOT NULL DEFAULT '{}',\n  position INTEGER NOT NULL DEFAULT 0\n);",
    "indexes": [
      "CREATE INDEX idx_events_org_timestamp ON events(org_id, timestamp DESC) - Primary query pattern for filtering by org and time",
      "CREATE INDEX idx_events_user_org ON events(user_id, org_id, timestamp DESC) - For user-specific analytics within org context",
      "CREATE INDEX idx_events_name ON events(org_id, event_name, timestamp DESC) - For filtering by event type",
      "CREATE INDEX idx_events_properties_gin ON events USING GIN(properties) - For querying arbitrary JSON properties",
      "CREATE INDEX idx_users_org ON users(org_id) - Fast membership checks",
      "No index on events.id - it's only for deletes/updates, rarely queried"
    ],
    "partitioning": "Partition events table by timestamp (daily or weekly range). Use LIST partitioning if using Postgres 11+ or declarative partitioning. Each partition holds 1-7 days of data. Makes old data deletion efficient (DROP PARTITION instead of DELETE). Also improves query planner by knowing time bounds. Create separate partitions per org if data volume is extremely high, but org_id filtering with indexes is usually sufficient.",
    "tradeoffs": "Optimized for read-heavy analytics workloads. Sacrificed: strict referential integrity on events.user_id (allowing NULLs means userless events are fine for tracking), real-time data freshness (batch writes possible), complex joins (denormalized org_id into events). JSONB for properties gives flexibility but consumes more storage than fixed columns. Daily partitioning balances query performance with maintenance overhead.",
    "sample_query": "SELECT \n  DATE(timestamp) as date,\n  COUNT(DISTINCT user_id) as active_users\nFROM events\nWHERE \n  org_id = 'org-uuid-here'\n  AND event_name = 'page_view'\n  AND timestamp >= NOW() - INTERVAL '30 days'\nGROUP BY DATE(timestamp)\nORDER BY date DESC;"
  },
  "section_d": {
    "issues": [
      {
        "category": "security",
        "severity": "critical",
        "problem": "Plain text password storage and comparison",
        "exploitation": "If database is compromised, all user passwords are exposed in plain text. An attacker can immediately use those credentials on other sites (credential stuffing). The string comparison is also vulnerable to timing attacks.",
        "fix": "Use bcrypt or argon2 for password hashing. Hash on registration, compare hash on login. Replace direct comparison with a timing-safe compare function."
      },
      {
        "category": "security",
        "severity": "critical",
        "problem": "Fallback to weak JWT secret in development",
        "exploitation": "If JWT_SECRET environment variable is missing in production, the code falls back to 'development-secret'. Attackers can forge tokens for any user and role, completely bypassing authentication.",
        "fix": "Remove the fallback entirely. Throw an error on startup if JWT_SECRET is not set. Make it a required environment variable with a strong random value."
      },
      {
        "category": "auth",
        "severity": "high",
        "problem": "No token revocation mechanism",
        "exploitation": "If a user's account is compromised or they need to be banned, the JWT remains valid for its full 7-day lifetime. Admins have no way to invalidate active tokens.",
        "fix": "Implement a token blacklist/revocation list in Redis. Store token jti (unique ID) or full hash with expiration matching the token. Check blacklist on every auth request. Or use short-lived access tokens (15 min) with refresh tokens."
      },
      {
        "category": "auth",
        "severity": "high",
        "problem": "Excessively long token lifetime",
        "exploitation": "7-day access tokens provide a large window for attackers if a token is stolen via XSS or network sniffing. No refresh token rotation means stolen tokens work for a week.",
        "fix": "Use short-lived access tokens (15-30 minutes) and separate refresh tokens stored in HttpOnly cookies. Implement refresh token rotation on each use."
      },
      {
        "category": "security",
        "severity": "high",
        "problem": "No password complexity requirements",
        "exploitation": "Users can set weak passwords like '123456'. Makes dictionary attacks and credential stuffing successful.",
        "fix": "Add validation during registration: minimum 8 characters, at least one uppercase, one lowercase, one number, one special character. Use a library like zod-password for validation."
      },
      {
        "category": "auth",
        "severity": "medium",
        "problem": "Authorization header parsing assumes 'Bearer' prefix",
        "exploitation": "If header is just 'token' (missing 'Bearer '), split(' ')[1] returns undefined. The code tries to extract token[1] which could crash or behave unexpectedly.",
        "fix": "Properly parse the header: check if it starts with 'Bearer ', then extract. Return 401 if format is incorrect. Use a library like express-bearer-token."
      },
      {
        "category": "performance",
        "severity": "medium",
        "problem": "Database query on every authenticated request",
        "exploitation": "Under high load, this extra DB query on every request creates unnecessary load. If the user table is large or slow, it affects all endpoints.",
        "fix": "Cache user active status in Redis. Or use a shorter token expiration and accept stale user status for a few minutes. Or include isActive in the JWT claim and accept eventual consistency."
      },
      {
        "category": "practices",
        "severity": "medium",
        "problem": "Generic error messages reveal user existence",
        "exploitation": "The login endpoint returns 'User not found' for non-existent emails and 'Invalid password' for wrong passwords. This allows attackers to enumerate which email addresses are registered.",
        "fix": "Return the same generic 'Invalid credentials' message for both cases to prevent email enumeration. Use the same timing for both branches."
      },
      {
        "category": "security",
        "severity": "low",
        "problem": "No rate limiting on authentication endpoints",
        "exploitation": "Brute force attacks against login endpoint are possible. An attacker can try thousands of password combinations without restriction.",
        "fix": "Implement rate limiting specifically for /login endpoint (e.g., 5 attempts per IP per 15 minutes). Use exponential backoff for repeated failures."
      },
      {
        "category": "practices",
        "severity": "low",
        "problem": "User role is trusted from JWT without verification",
        "exploitation": "If an attacker somehow forges or manipulates a token (or the secret is weak), they can escalate privileges by changing the role claim in the token.",
        "fix": "Fetch the user's current role from the database in authMiddleware and override the claim. Or at least validate that the role is one of the allowed values."
      }
    ]
  }
}
